{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Data-Science-and-Data-Analytics-Courses/MITx---Machine-Learning-with-Python-From-Linear-Models-to-Deep-Learning-Jun-11-2019/blob/master/Unit%201%20Linear%20Classifiers%20and%20Generalizations%20(2%20weeks)/Project%201%3A%20Automatic%20Review%20Analyzer/Project1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI45ce2OcpDu",
        "colab_type": "text"
      },
      "source": [
        "# Project 1: Automatic Review Analyzer\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRrOetKsg-RC",
        "colab_type": "text"
      },
      "source": [
        "## Packages and libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPcqYdOIxzAU",
        "colab_type": "code",
        "outputId": "044c1ec3-e479-4bc9-bc58-8a6314c49464",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import sys\n",
        "\n",
        "url = \"https://github.com/Data-Science-and-Data-Analytics-Courses/Notebook-Library\"\n",
        "\n",
        "!git clone \"{url}\" \"/nblib\"\n",
        "%run \"/nblib/.Importable.ipynb\"\n",
        "sys.path.append(\"/\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '/nblib'...\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Counting objects:   3% (1/26)   \u001b[K\rremote: Counting objects:   7% (2/26)   \u001b[K\rremote: Counting objects:  11% (3/26)   \u001b[K\rremote: Counting objects:  15% (4/26)   \u001b[K\rremote: Counting objects:  19% (5/26)   \u001b[K\rremote: Counting objects:  23% (6/26)   \u001b[K\rremote: Counting objects:  26% (7/26)   \u001b[K\rremote: Counting objects:  30% (8/26)   \u001b[K\rremote: Counting objects:  34% (9/26)   \u001b[K\rremote: Counting objects:  38% (10/26)   \u001b[K\rremote: Counting objects:  42% (11/26)   \u001b[K\rremote: Counting objects:  46% (12/26)   \u001b[K\rremote: Counting objects:  50% (13/26)   \u001b[K\rremote: Counting objects:  53% (14/26)   \u001b[K\rremote: Counting objects:  57% (15/26)   \u001b[K\rremote: Counting objects:  61% (16/26)   \u001b[K\rremote: Counting objects:  65% (17/26)   \u001b[K\rremote: Counting objects:  69% (18/26)   \u001b[K\rremote: Counting objects:  73% (19/26)   \u001b[K\rremote: Counting objects:  76% (20/26)   \u001b[K\rremote: Counting objects:  80% (21/26)   \u001b[K\rremote: Counting objects:  84% (22/26)   \u001b[K\rremote: Counting objects:  88% (23/26)   \u001b[K\rremote: Counting objects:  92% (24/26)   \u001b[K\rremote: Counting objects:  96% (25/26)   \u001b[K\rremote: Counting objects: 100% (26/26)   \u001b[K\rremote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects:   4% (1/23)   \u001b[K\rremote: Compressing objects:   8% (2/23)   \u001b[K\rremote: Compressing objects:  13% (3/23)   \u001b[K\rremote: Compressing objects:  17% (4/23)   \u001b[K\rremote: Compressing objects:  21% (5/23)   \u001b[K\rremote: Compressing objects:  26% (6/23)   \u001b[K\rremote: Compressing objects:  30% (7/23)   \u001b[K\rremote: Compressing objects:  34% (8/23)   \u001b[K\rremote: Compressing objects:  39% (9/23)   \u001b[K\rremote: Compressing objects:  43% (10/23)   \u001b[K\rremote: Compressing objects:  47% (11/23)   \u001b[K\rremote: Compressing objects:  52% (12/23)   \u001b[K\rremote: Compressing objects:  56% (13/23)   \u001b[K\rremote: Compressing objects:  60% (14/23)   \u001b[K\rremote: Compressing objects:  65% (15/23)   \u001b[K\rremote: Compressing objects:  69% (16/23)   \u001b[K\rremote: Compressing objects:  73% (17/23)   \u001b[K\rremote: Compressing objects:  78% (18/23)   \u001b[K\rremote: Compressing objects:  82% (19/23)   \u001b[K\rremote: Compressing objects:  86% (20/23)   \u001b[K\rremote: Compressing objects:  91% (21/23)   \u001b[K\rremote: Compressing objects:  95% (22/23)   \u001b[K\rremote: Compressing objects: 100% (23/23)   \u001b[K\rremote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 26 (delta 12), reused 7 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects:   3% (1/26)   \rUnpacking objects:   7% (2/26)   \rUnpacking objects:  11% (3/26)   \rUnpacking objects:  15% (4/26)   \rUnpacking objects:  19% (5/26)   \rUnpacking objects:  23% (6/26)   \rUnpacking objects:  26% (7/26)   \rUnpacking objects:  30% (8/26)   \rUnpacking objects:  34% (9/26)   \rUnpacking objects:  38% (10/26)   \rUnpacking objects:  42% (11/26)   \rUnpacking objects:  46% (12/26)   \rUnpacking objects:  50% (13/26)   \rUnpacking objects:  53% (14/26)   \rUnpacking objects:  57% (15/26)   \rUnpacking objects:  61% (16/26)   \rUnpacking objects:  65% (17/26)   \rUnpacking objects:  69% (18/26)   \rUnpacking objects:  73% (19/26)   \rUnpacking objects:  76% (20/26)   \rUnpacking objects:  80% (21/26)   \rUnpacking objects:  84% (22/26)   \rUnpacking objects:  88% (23/26)   \rUnpacking objects:  92% (24/26)   \rUnpacking objects:  96% (25/26)   \rUnpacking objects: 100% (26/26)   \rUnpacking objects: 100% (26/26), done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<style type='text/css'>\n",
              ".hll { background-color: #ffffcc }\n",
              ".c { color: #408080; font-style: italic } /* Comment */\n",
              ".err { border: 1px solid #FF0000 } /* Error */\n",
              ".k { color: #008000; font-weight: bold } /* Keyword */\n",
              ".o { color: #666666 } /* Operator */\n",
              ".ch { color: #408080; font-style: italic } /* Comment.Hashbang */\n",
              ".cm { color: #408080; font-style: italic } /* Comment.Multiline */\n",
              ".cp { color: #BC7A00 } /* Comment.Preproc */\n",
              ".cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */\n",
              ".c1 { color: #408080; font-style: italic } /* Comment.Single */\n",
              ".cs { color: #408080; font-style: italic } /* Comment.Special */\n",
              ".gd { color: #A00000 } /* Generic.Deleted */\n",
              ".ge { font-style: italic } /* Generic.Emph */\n",
              ".gr { color: #FF0000 } /* Generic.Error */\n",
              ".gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
              ".gi { color: #00A000 } /* Generic.Inserted */\n",
              ".go { color: #888888 } /* Generic.Output */\n",
              ".gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
              ".gs { font-weight: bold } /* Generic.Strong */\n",
              ".gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
              ".gt { color: #0044DD } /* Generic.Traceback */\n",
              ".kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
              ".kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
              ".kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
              ".kp { color: #008000 } /* Keyword.Pseudo */\n",
              ".kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
              ".kt { color: #B00040 } /* Keyword.Type */\n",
              ".m { color: #666666 } /* Literal.Number */\n",
              ".s { color: #BA2121 } /* Literal.String */\n",
              ".na { color: #7D9029 } /* Name.Attribute */\n",
              ".nb { color: #008000 } /* Name.Builtin */\n",
              ".nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
              ".no { color: #880000 } /* Name.Constant */\n",
              ".nd { color: #AA22FF } /* Name.Decorator */\n",
              ".ni { color: #999999; font-weight: bold } /* Name.Entity */\n",
              ".ne { color: #D2413A; font-weight: bold } /* Name.Exception */\n",
              ".nf { color: #0000FF } /* Name.Function */\n",
              ".nl { color: #A0A000 } /* Name.Label */\n",
              ".nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
              ".nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
              ".nv { color: #19177C } /* Name.Variable */\n",
              ".ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
              ".w { color: #bbbbbb } /* Text.Whitespace */\n",
              ".mb { color: #666666 } /* Literal.Number.Bin */\n",
              ".mf { color: #666666 } /* Literal.Number.Float */\n",
              ".mh { color: #666666 } /* Literal.Number.Hex */\n",
              ".mi { color: #666666 } /* Literal.Number.Integer */\n",
              ".mo { color: #666666 } /* Literal.Number.Oct */\n",
              ".sb { color: #BA2121 } /* Literal.String.Backtick */\n",
              ".sc { color: #BA2121 } /* Literal.String.Char */\n",
              ".sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
              ".s2 { color: #BA2121 } /* Literal.String.Double */\n",
              ".se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */\n",
              ".sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
              ".si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */\n",
              ".sx { color: #008000 } /* Literal.String.Other */\n",
              ".sr { color: #BB6688 } /* Literal.String.Regex */\n",
              ".s1 { color: #BA2121 } /* Literal.String.Single */\n",
              ".ss { color: #19177C } /* Literal.String.Symbol */\n",
              ".bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
              ".vc { color: #19177C } /* Name.Variable.Class */\n",
              ".vg { color: #19177C } /* Name.Variable.Global */\n",
              ".vi { color: #19177C } /* Name.Variable.Instance */\n",
              ".il { color: #666666 } /* Literal.Number.Integer.Long */\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Egs1NStV-d23",
        "outputId": "f853ca29-c67a-4422-bf59-f96e2e097baf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "from google.colab import drive\n",
        "from nblib import Git\n",
        "\n",
        "URL = \"https://github.com/Data-Science-and-Data-Analytics-Courses/MITx---Machine-Learning-with-Python-From-Linear-Models-to-Deep-Learning-Jun-11-2019\"\n",
        "nbdir_rel = \"Unit 1 Linear Classifiers and Generalizations (2 weeks)/Project 1: Automatic Review Analyzer/\"\n",
        "\n",
        "REPO = Git.clone(URL)\n",
        "NBDIR = REPO/nbdir_rel\n",
        "os.chdir(NBDIR)\n",
        "sys.path.append(NBDIR.as_posix())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "importing Jupyter notebook from /nblib/Git.ipynb\n",
            "Cloning into '/content/MITx---Machine-Learning-with-Python-From-Linear-Models-to-Deep-Learning-Jun-11-2019'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 165 (delta 6), reused 0 (delta 0), pack-reused 149\u001b[K\n",
            "Receiving objects: 100% (165/165), 1.24 MiB | 16.87 MiB/s, done.\n",
            "Resolving deltas: 100% (76/76), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTGAoWPVKhi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sentiment_analysis.project1 import get_order\n",
        "\n",
        "from pathlib import Path\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5sl8tFrDP67Z"
      },
      "source": [
        "## Hinge Loss\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTwFNVtH71cP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hinge_loss_single(feature_vector, label, theta, theta_0):\n",
        "    \"\"\"\n",
        "    Finds the hinge loss on a single data point given specific classification\n",
        "    parameters.\n",
        "\n",
        "    Args:\n",
        "        feature_vector - A numpy array describing the given data point.\n",
        "        label - A real valued number, the correct classification of the data\n",
        "            point.\n",
        "        theta - A numpy array describing the linear classifier.\n",
        "        theta_0 - A real valued number representing the offset parameter.\n",
        "\n",
        "\n",
        "    Returns: A real number representing the hinge loss associated with the\n",
        "    given data point and parameters.\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    pred = np.dot(theta, feature_vector) + theta_0\n",
        "    loss = max(0, 1-label*pred)\n",
        "    \n",
        "    return loss\n",
        "  \n",
        "feature_vector = np.array([1, 2])\n",
        "label, theta, theta_0 = 1, np.array([-1, 1]), -0.2\n",
        "exp_res = 1 - 0.8\n",
        "assert exp_res == hinge_loss_single(feature_vector, label, theta, theta_0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMCa4w4W-O0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hinge_loss_full(feature_matrix, labels, theta, theta_0):\n",
        "    \"\"\"\n",
        "    Finds the total hinge loss on a set of data given specific classification\n",
        "    parameters.\n",
        "\n",
        "    Args:\n",
        "        feature_matrix - A numpy matrix describing the given data. Each row\n",
        "            represents a single data point.\n",
        "        labels - A numpy array where the kth element of the array is the\n",
        "            correct classification of the kth row of the feature matrix.\n",
        "        theta - A numpy array describing the linear classifier.\n",
        "        theta_0 - A real valued number representing the offset parameter.\n",
        "\n",
        "\n",
        "    Returns: A real number representing the hinge loss associated with the\n",
        "    given dataset and parameters. This number should be the average hinge\n",
        "    loss across all of the points in the feature matrix.\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    predictions = np.dot(feature_matrix, theta) + theta_0\n",
        "    losses = np.maximum(np.zeros(len(predictions)), 1 - labels * predictions)\n",
        "    loss = np.mean(losses)\n",
        "    \n",
        "    return loss\n",
        "\n",
        "feature_matrix = np.array([[1, 2], [1, 2]])\n",
        "labels, theta, theta_0 = np.array([1, 1]), np.array([-1, 1]), -0.2\n",
        "exp_res = 1 - 0.8\n",
        "assert exp_res == hinge_loss_full(feature_matrix, labels, theta, theta_0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsKVVNGZnERg",
        "colab_type": "text"
      },
      "source": [
        "## Perceptron Algorithm\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiYN3HyYnJ8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perceptron_single_step_update(\n",
        "        feature_vector,\n",
        "        label,\n",
        "        current_theta,\n",
        "        current_theta_0):\n",
        "    \"\"\"\n",
        "    Properly updates the classification parameter, theta and theta_0, on a\n",
        "    single step of the perceptron algorithm.\n",
        "\n",
        "    Args:\n",
        "        feature_vector - A numpy array describing a single data point.\n",
        "        label - The correct classification of the feature vector.\n",
        "        current_theta - The current theta being used by the perceptron\n",
        "            algorithm before this update.\n",
        "        current_theta_0 - The current theta_0 being used by the perceptron\n",
        "            algorithm before this update.\n",
        "\n",
        "    Returns: A tuple where the first element is a numpy array with the value of\n",
        "    theta after the current update has completed and the second element is a\n",
        "    real valued number with the value of theta_0 after the current updated has\n",
        "    completed.\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    theta = np.array(current_theta)\n",
        "    theta_0 = current_theta_0\n",
        "    if label * (theta.dot(feature_vector) + theta_0) <= 0: # misclassified\n",
        "      theta += label * feature_vector # update theta\n",
        "      theta_0 += label # update theta 0\n",
        "    \n",
        "    return theta, theta_0\n",
        "    \n",
        "feature_vector = np.array([1, 2])\n",
        "label, theta, theta_0 = 1, np.array([-1, 1]), -1.5\n",
        "exp_theta, exp_theta_0 = (np.array([0, 3]), -0.5)\n",
        "upd_theta, upd_theta_0 = perceptron_single_step_update(feature_vector, label, theta, theta_0)\n",
        "assert np.all(upd_theta == exp_theta)\n",
        "assert upd_theta_0 == exp_theta_0\n",
        "\n",
        "feature_vector = np.array([1, 2])\n",
        "label, theta, theta_0 = 1, np.array([-1, 1]), -1\n",
        "exp_theta, exp_theta_0 = (np.array([0, 3]), 0)\n",
        "upd_theta, upd_theta_0 = perceptron_single_step_update(feature_vector, label, theta, theta_0)\n",
        "assert np.all(upd_theta == exp_theta)\n",
        "assert upd_theta_0 == exp_theta_0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k50IeQxCw9uc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perceptron(feature_matrix, labels, T):\n",
        "    \"\"\"\n",
        "    Runs the full perceptron algorithm on a given set of data. Runs T\n",
        "    iterations through the data set, there is no need to worry about\n",
        "    stopping early.\n",
        "\n",
        "    NOTE: Please use the previously implemented functions when applicable.\n",
        "    Do not copy paste code from previous parts.\n",
        "\n",
        "    NOTE: Iterate the data matrix by the orders returned by get_order(feature_matrix.shape[0])\n",
        "\n",
        "    Args:\n",
        "        feature_matrix -  A numpy matrix describing the given data. Each row\n",
        "            represents a single data point.\n",
        "        labels - A numpy array where the kth element of the array is the\n",
        "            correct classification of the kth row of the feature matrix.\n",
        "        T - An integer indicating how many times the perceptron algorithm\n",
        "            should iterate through the feature matrix.\n",
        "\n",
        "    Returns: A tuple where the first element is a numpy array with the value of\n",
        "    theta, the linear classification parameter, after T iterations through the\n",
        "    feature matrix and the second element is a real number with the value of\n",
        "    theta_0, the offset classification parameter, after T iterations through\n",
        "    the feature matrix.\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    theta, theta_0 = np.zeros(feature_matrix.shape[1]), 0\n",
        "    for t in range(T):\n",
        "        for i in get_order(feature_matrix.shape[0]):\n",
        "            # Your code here\n",
        "            if labels[i] * (theta.dot(feature_matrix[i]) + theta_0) <= 0: # misclassified\n",
        "              theta += labels[i] * feature_matrix[i] # update theta\n",
        "              theta_0 += labels[i] # update theta 0\n",
        "              \n",
        "    return theta, theta_0\n",
        "\n",
        "def test_perceptron(feature_matrix, labels, T, exp_theta, exp_theta_0):\n",
        "  theta, theta_0 = perceptron(feature_matrix, labels, T)\n",
        "  assert np.all(theta == exp_theta)\n",
        "  assert theta_0 == exp_theta_0\n",
        "  \n",
        "feature_matrix = np.array([[1, 2]])\n",
        "labels = np.array([1])\n",
        "T = 1\n",
        "exp_theta, exp_theta_0 = (np.array([1, 2]), 1)\n",
        "test_perceptron(feature_matrix, labels, T, exp_theta, exp_theta_0)\n",
        "\n",
        "feature_matrix = np.array([[1, 2], [-1, 0]])\n",
        "labels = np.array([1, 1])\n",
        "T = 1\n",
        "exp_theta, exp_theta_0 = (np.array([0, 2]), 2)\n",
        "test_perceptron(feature_matrix, labels, T, exp_theta, exp_theta_0)\n",
        "\n",
        "feature_matrix = np.array([[1, 2]])\n",
        "labels = np.array([1])\n",
        "T = 2\n",
        "exp_theta, exp_theta_0 = (np.array([1, 2]), 1)\n",
        "test_perceptron(feature_matrix, labels, T, exp_theta, exp_theta_0)\n",
        "\n",
        "feature_matrix = np.array([[1, 2], [-1, 0]])\n",
        "labels = np.array([1, 1])\n",
        "T = 2\n",
        "exp_theta, exp_theta_0 = (np.array([0, 2]), 2)\n",
        "test_perceptron(feature_matrix, labels, T, exp_theta, exp_theta_0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCVz2VmrWLSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def average_perceptron(feature_matrix, labels, T):\n",
        "    \"\"\"\n",
        "    Runs the average perceptron algorithm on a given set of data. Runs T\n",
        "    iterations through the data set, there is no need to worry about\n",
        "    stopping early.\n",
        "\n",
        "    NOTE: Please use the previously implemented functions when applicable.\n",
        "    Do not copy paste code from previous parts.\n",
        "\n",
        "    NOTE: Iterate the data matrix by the orders returned by get_order(feature_matrix.shape[0])\n",
        "\n",
        "\n",
        "    Args:\n",
        "        feature_matrix -  A numpy matrix describing the given data. Each row\n",
        "            represents a single data point.\n",
        "        labels - A numpy array where the kth element of the array is the\n",
        "            correct classification of the kth row of the feature matrix.\n",
        "        T - An integer indicating how many times the perceptron algorithm\n",
        "            should iterate through the feature matrix.\n",
        "\n",
        "    Returns: A tuple where the first element is a numpy array with the value of\n",
        "    the average theta, the linear classification parameter, found after T\n",
        "    iterations through the feature matrix and the second element is a real\n",
        "    number with the value of the average theta_0, the offset classification\n",
        "    parameter, found after T iterations through the feature matrix.\n",
        "\n",
        "    Hint: It is difficult to keep a running average; however, it is simple to\n",
        "    find a sum and divide.\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    theta, theta_0 = np.zeros(feature_matrix.shape[1]), 0\n",
        "    theta_sum, theta_0_sum = np.zeros(feature_matrix.shape[1]), 0\n",
        "    for t in range(T):\n",
        "        for i in get_order(feature_matrix.shape[0]):\n",
        "            # Your code here\n",
        "            if labels[i] * (theta.dot(feature_matrix[i]) + theta_0) <= 0: # misclassified\n",
        "              theta += labels[i] * feature_matrix[i] # update theta\n",
        "              theta_0 += labels[i] # update theta 0\n",
        "            theta_sum += theta\n",
        "            theta_0_sum += theta_0\n",
        "    \n",
        "    theta_avg = theta_sum / (feature_matrix.shape[0] * T)\n",
        "    theta_0_avg = theta_0_sum / (feature_matrix.shape[0] * T)\n",
        "              \n",
        "    return theta_avg, theta_0_avg\n",
        "\n",
        "def test_average_perceptron(feature_matrix, labels, T, exp_theta, exp_theta_0):\n",
        "  theta_avg, theta_0_avg = average_perceptron(feature_matrix, labels, T)\n",
        "  assert np.all(theta_avg == exp_theta)\n",
        "  assert theta_0_avg == exp_theta_0\n",
        "\n",
        "feature_matrix = np.array([[1, 2]])\n",
        "labels = np.array([1])\n",
        "T = 1\n",
        "exp_theta, exp_theta_0 = (np.array([1, 2]), 1)\n",
        "test_average_perceptron(feature_matrix, labels, T, exp_theta, exp_theta_0)\n",
        "\n",
        "feature_matrix = np.array([[1, 2], [-1, 0]])\n",
        "labels = np.array([1, 1])\n",
        "T = 1\n",
        "exp_theta, exp_theta_0 = (np.array([-0.5, 1]), 1.5)\n",
        "test_average_perceptron(feature_matrix, labels, T, exp_theta, exp_theta_0)\n",
        "\n",
        "feature_matrix = np.array([[1, 2]])\n",
        "labels = np.array([1])\n",
        "T = 2\n",
        "exp_theta, exp_theta_0 = (np.array([1, 2]), 1)\n",
        "test_average_perceptron(feature_matrix, labels, T, exp_theta, exp_theta_0)\n",
        "\n",
        "feature_matrix = np.array([[1, 2], [-1, 0]])\n",
        "labels = np.array([1, 1])\n",
        "T = 2\n",
        "exp_theta, exp_theta_0 = (np.array([-0.25, 1.5]), 1.75)\n",
        "test_average_perceptron(feature_matrix, labels, T, exp_theta, exp_theta_0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RpviN1ucSPg",
        "colab_type": "text"
      },
      "source": [
        "## Pegasos Algorithm\n",
        "[Pegasos: Primal Estimated sub-GrAdient\n",
        "SOlver for SVM](https://prod-edxapp.edx-cdn.org/assets/courseware/v1/16f13f7ac37ae86ebe0372f2410bcec4/asset-v1:MITx+6.86x+1T2019+type@asset+block/resources_pegasos.pdf)  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCTLvW4ycVIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pegasos_single_step_update(\n",
        "        feature_vector,\n",
        "        label,\n",
        "        L,\n",
        "        eta,\n",
        "        current_theta,\n",
        "        current_theta_0):\n",
        "    \"\"\"\n",
        "    Properly updates the classification parameter, theta and theta_0, on a\n",
        "    single step of the Pegasos algorithm\n",
        "\n",
        "    Args:\n",
        "        feature_vector - A numpy array describing a single data point.\n",
        "        label - The correct classification of the feature vector.\n",
        "        L - The lamba value being used to update the parameters.\n",
        "        eta - Learning rate to update parameters.\n",
        "        current_theta - The current theta being used by the Pegasos\n",
        "            algorithm before this update.\n",
        "        current_theta_0 - The current theta_0 being used by the\n",
        "            Pegasos algorithm before this update.\n",
        "\n",
        "    Returns: A tuple where the first element is a numpy array with the value of\n",
        "    theta after the current update has completed and the second element is a\n",
        "    real valued number with the value of theta_0 after the current updated has\n",
        "    completed.\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    raise NotImplementedError\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}